{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c35aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Rush Hour Analysis most recent year\n",
    "\n",
    "df['time_dt'] = pd.to_datetime(df['time_full_str'])\n",
    "start_date = pd.Timestamp(f\"2024-10-01\")\n",
    "end_date = pd.Timestamp(f\"2025-09-30\")\n",
    "all_data = df[(df['time_dt'] <= end_date) & (df['time_dt'] >= start_date) & (df['time_dt'].dt.weekday < 5) & (df['trip_dist'] >= 10) & (df['mode'] == 0)].copy()\n",
    "\n",
    "hour = all_data['time_dt'].dt.hour\n",
    "is_rush_hour = ((hour >= 8) & (hour < 10)) | ((hour >= 17) & (hour < 19))\n",
    "all_data['period'] = 'Non-Rush Hour'\n",
    "all_data.loc[is_rush_hour, 'period'] = 'Rush Hour'\n",
    "\n",
    "grouping_cols = ['tripid', 'cityname_corrected', 'lat_orig', 'lon_orig', 'lat_dest', 'lon_dest', 'trip_dist', 'period']\n",
    "agg_times = all_data.groupby(grouping_cols)['traffic_min'].agg(['median', 'count']).reset_index()\n",
    "\n",
    "comparison_table = agg_times.pivot_table(\n",
    "    index=[col for col in grouping_cols if col != 'period'],\n",
    "    columns='period',\n",
    "    values=['median', 'count']\n",
    ").reset_index()\n",
    "\n",
    "comparison_table.columns = ['_'.join(col).strip() if isinstance(col, tuple) else col for col in comparison_table.columns.values]\n",
    "comparison_table.rename(columns={\n",
    "    'median_Non-Rush Hour': 'median_non_rush_hour',\n",
    "    'median_Rush Hour': 'median_rush_hour',\n",
    "    'count_Non-Rush Hour': 'count_non_rush_hour',\n",
    "    'count_Rush Hour': 'count_rush_hour',\n",
    "    'tripid_': 'tripid',\n",
    "    'mode_': 'mode',\n",
    "    'cityname_corrected_': 'cityname_corrected',\n",
    "    'lat_orig_': 'lat_orig',\n",
    "    'lon_orig_': 'lon_orig',\n",
    "    'lat_dest_': 'lat_dest',\n",
    "    'lon_dest_': 'lon_dest',\n",
    "    'trip_dist_': 'trip_dist'\n",
    "}, inplace=True)\n",
    "\n",
    "comparison_table.fillna(0, inplace=True)\n",
    "comparison_table[\"rush_hour_diff\"] = comparison_table['median_rush_hour'] - comparison_table['median_non_rush_hour']\n",
    "comparison_table['rush_hour_impact'] = ((comparison_table['median_rush_hour'] - comparison_table['median_non_rush_hour']) / comparison_table['median_non_rush_hour']) * 100\n",
    "\n",
    "for col in ['count_non_rush_hour', 'count_rush_hour']:\n",
    "    if col in comparison_table.columns:\n",
    "        comparison_table[col] = comparison_table[col].astype(int)\n",
    "\n",
    "comparison_table['origin'] = comparison_table['lat_orig'].astype(str) + ',' + comparison_table['lon_orig'].astype(str)\n",
    "comparison_table['dest'] = comparison_table['lat_dest'].astype(str) + ',' + comparison_table['lon_dest'].astype(str)\n",
    "\n",
    "final_table = comparison_table.sort_values('rush_hour_diff', ascending=False)\n",
    "display(final_table[(final_table[\"count_non_rush_hour\"] >= 3) & (final_table[\"count_rush_hour\"] >= 3)][['tripid', 'cityname_corrected', 'origin', 'dest', 'trip_dist', 'median_non_rush_hour', 'median_rush_hour', 'rush_hour_impact', 'count_non_rush_hour', 'count_rush_hour']].head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4706c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouping_cols = ['tripid', 'cityname_corrected', 'lat_orig', 'lon_orig', 'lat_dest', 'lon_dest', 'trip_dist', 'period']\n",
    "agg_times = all_data.groupby(grouping_cols)['traffic_min'].agg(['median', 'count']).reset_index()\n",
    "\n",
    "comparison_table = agg_times.pivot_table(\n",
    "    index=[col for col in grouping_cols if col != 'period'],\n",
    "    columns='period',\n",
    "    values=['median', 'count']\n",
    ").reset_index()\n",
    "\n",
    "comparison_table.columns = ['_'.join(col).strip() if isinstance(col, tuple) else col for col in comparison_table.columns.values]\n",
    "comparison_table.rename(columns={\n",
    "    'median_Non-Rush Hour': 'median_non_rush_hour',\n",
    "    'median_Rush Hour': 'median_rush_hour',\n",
    "    'count_Non-Rush Hour': 'count_non_rush_hour',\n",
    "    'count_Rush Hour': 'count_rush_hour',\n",
    "    'tripid_': 'tripid',\n",
    "    'mode_': 'mode',\n",
    "    'cityname_corrected_': 'cityname_corrected',\n",
    "    'lat_orig_': 'lat_orig',\n",
    "    'lon_orig_': 'lon_orig',\n",
    "    'lat_dest_': 'lat_dest',\n",
    "    'lon_dest_': 'lon_dest',\n",
    "    'trip_dist_': 'trip_dist'\n",
    "}, inplace=True)\n",
    "\n",
    "comparison_table.fillna(0, inplace=True)\n",
    "comparison_table[\"rush_hour_diff\"] = comparison_table['median_rush_hour'] - comparison_table['median_non_rush_hour']\n",
    "comparison_table['rush_hour_impact'] = ((comparison_table['median_rush_hour'] - comparison_table['median_non_rush_hour']) / comparison_table['median_non_rush_hour']) * 100\n",
    "\n",
    "for col in ['count_non_rush_hour', 'count_rush_hour']:\n",
    "    if col in comparison_table.columns:\n",
    "        comparison_table[col] = comparison_table[col].astype(int)\n",
    "\n",
    "comparison_table['origin'] = comparison_table['lat_orig'].astype(str) + ',' + comparison_table['lon_orig'].astype(str)\n",
    "comparison_table['dest'] = comparison_table['lat_dest'].astype(str) + ',' + comparison_table['lon_dest'].astype(str)\n",
    "\n",
    "final_table = comparison_table.sort_values('rush_hour_diff', ascending=False)\n",
    "display(final_table[(final_table[\"count_non_rush_hour\"] >= 3) & (final_table[\"count_rush_hour\"] >= 3)][['tripid', 'cityname_corrected', 'origin', 'dest', 'trip_dist', 'median_non_rush_hour', 'median_rush_hour', 'rush_hour_impact', 'count_non_rush_hour', 'count_rush_hour']].head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6e243f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to float32 to save memory\n",
    "all_data['lat_orig'] = all_data['lat_orig'].astype(np.float32)\n",
    "all_data['lon_orig'] = all_data['lon_orig'].astype(np.float32)\n",
    "all_data['lat_dest'] = all_data['lat_dest'].astype(np.float32)\n",
    "all_data['lon_dest'] = all_data['lon_dest'].astype(np.float32)\n",
    "\n",
    "def cluster_and_assign(full_coords, sample_size=10000, eps_km=0.5):\n",
    "    # Sample for clustering\n",
    "    if len(full_coords) > sample_size:\n",
    "        sample_idx = np.random.choice(len(full_coords), sample_size, replace=False)\n",
    "        sample_coords = full_coords[sample_idx]\n",
    "    else:\n",
    "        sample_idx = np.arange(len(full_coords))\n",
    "        sample_coords = full_coords\n",
    "\n",
    "    # Cluster the sample\n",
    "    db = DBSCAN(eps=eps_km/6371, min_samples=1, metric='haversine', algorithm='ball_tree')\n",
    "    db.fit(np.radians(sample_coords))\n",
    "    sample_labels = db.labels_\n",
    "\n",
    "    # Assign clusters to all points using nearest neighbor in the sample\n",
    "    tree = BallTree(np.radians(sample_coords), metric='haversine')\n",
    "    dist, ind = tree.query(np.radians(full_coords), k=1)\n",
    "    assigned_labels = sample_labels[ind.flatten()]\n",
    "    return assigned_labels\n",
    "\n",
    "# Cluster origins\n",
    "orig_coords = all_data[['lat_orig', 'lon_orig']].values\n",
    "all_data['origin_cluster'] = cluster_and_assign(orig_coords)\n",
    "\n",
    "# Cluster destinations\n",
    "dest_coords = all_data[['lat_dest', 'lon_dest']].values\n",
    "all_data['dest_cluster'] = cluster_and_assign(dest_coords)\n",
    "\n",
    "# Combine both clusters to define a route group\n",
    "all_data['route_group'] = all_data['origin_cluster'].astype(str) + '_' + all_data['dest_cluster'].astype(str)\n",
    "\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871b8ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Rush Hour Analysis by Route Group (without trip_dist in grouping) ---\n",
    "# This cell groups by route_group and computes rush hour/non-rush hour comparison as before, then merges trip_dist back in\n",
    "\n",
    "grouping_cols = ['route_group', 'cityname_corrected', 'period']\n",
    "\n",
    "# Ensure 'period' column exists\n",
    "if 'period' not in all_data.columns:\n",
    "    hour = all_data['time_dt'].dt.hour\n",
    "    is_rush_hour = ((hour >= 8) & (hour < 10)) | ((hour >= 17) & (hour < 19))\n",
    "    all_data['period'] = 'Non-Rush Hour'\n",
    "    all_data.loc[is_rush_hour, 'period'] = 'Rush Hour'\n",
    "\n",
    "agg_times = all_data.groupby(grouping_cols)['traffic_min'].agg(['mean', 'count']).reset_index()\n",
    "\n",
    "comparison_table = agg_times.pivot_table(\n",
    "    index=[col for col in grouping_cols if col != 'period'],\n",
    "    columns='period',\n",
    "    values=['mean', 'count']\n",
    ").reset_index()\n",
    "\n",
    "comparison_table.columns = ['_'.join(col).strip() if isinstance(col, tuple) else col for col in comparison_table.columns.values]\n",
    "comparison_table.rename(columns={\n",
    "    'mean_Non-Rush Hour': 'mean_non_rush_hour',\n",
    "    'mean_Rush Hour': 'mean_rush_hour',\n",
    "    'count_Non-Rush Hour': 'count_non_rush_hour',\n",
    "    'count_Rush Hour': 'count_rush_hour',\n",
    "    'route_group_': 'route_group',\n",
    "    'cityname_corrected_': 'cityname_corrected'\n",
    "}, inplace=True)\n",
    "\n",
    "comparison_table.fillna(0, inplace=True)\n",
    "comparison_table[\"rush_hour_diff\"] = comparison_table['mean_rush_hour'] - comparison_table['mean_non_rush_hour']\n",
    "# comparison_table['rush_hour_impact'] = ((comparison_table['mean_rush_hour'] - comparison_table['mean_non_rush_hour']) / comparison_table['mean_non_rush_hour']) * 100\n",
    "\n",
    "for col in ['count_non_rush_hour', 'count_rush_hour']:\n",
    "    if col in comparison_table.columns:\n",
    "        comparison_table[col] = comparison_table[col].astype(int)\n",
    "\n",
    "# Merge trip_dist back in (using first value for each route_group)\n",
    "trip_dist_map = all_data.groupby('route_group')[['trip_dist', \"origin\", \"dest\"]].first().reset_index()\n",
    "comparison_table = comparison_table.merge(trip_dist_map, on='route_group', how='left')\n",
    "\n",
    "# Show top 20 grouped routes by rush hour impact\n",
    "comparison_table = comparison_table.sort_values('rush_hour_diff', ascending=False)\n",
    "display_table = comparison_table[(comparison_table[\"count_non_rush_hour\"] >= 20) & (comparison_table[\"count_rush_hour\"] >= 15)][['route_group', 'cityname_corrected', 'trip_dist', \"origin\", \"dest\", 'mean_non_rush_hour', 'median_rush_hour', 'count_non_rush_hour', 'count_rush_hour', \"rush_hour_diff\"]]\n",
    "display_table.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c0f491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save top-3 route maps per city into ./plots_by_route\n",
    "import pathlib\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "\n",
    "out_dir = pathlib.Path('plots_by_route')\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Reconstruct line_gdf/poly_gdf from results if needed\n",
    "if 'line_gdf' not in globals() and 'results' in globals() and results:\n",
    "    line_gdf = gpd.GeoDataFrame(results, geometry='linestring', crs='EPSG:4326')\n",
    "    line_gdf = line_gdf.set_geometry('linestring')\n",
    "if 'poly_gdf' not in globals() and 'line_gdf' in globals():\n",
    "    line_gdf_web = line_gdf.to_crs(epsg=3857)\n",
    "    line_gdf_web['polygon_100m'] = line_gdf_web.geometry.buffer(100)\n",
    "    poly_gdf = gpd.GeoDataFrame(line_gdf_web.copy(), geometry=line_gdf_web['polygon_100m'], crs=line_gdf_web.crs).to_crs(epsg=4326)\n",
    "\n",
    "def safe(s):\n",
    "    if s is None:\n",
    "        return 'unknown'\n",
    "    s = str(s)\n",
    "    s = re.sub(r'[^A-Za-z0-9_\\-]', '_', s)\n",
    "    return s[:180]\n",
    "\n",
    "if 'final_table' not in globals():\n",
    "    raise RuntimeError('`final_table` not found. Run the Rush Hour Analysis cell first.')\n",
    "\n",
    "ft = final_table.reset_index()\n",
    "if 'rank' not in ft.columns:\n",
    "    ft.insert(0, 'rank', range(1, len(ft) + 1))\n",
    "\n",
    "for city in ft['cityname_corrected'].unique():\n",
    "    city_rows = ft[ft['cityname_corrected'] == city].sort_values('rush_vs_freeflow_diff', ascending=False).head(3)\n",
    "    if city_rows.empty:\n",
    "        continue\n",
    "    for _, crow in city_rows.iterrows():\n",
    "        rank = int(crow.get('rank', -1))\n",
    "        tripid = crow.get('tripid')\n",
    "        match = None\n",
    "        if 'line_gdf' in globals():\n",
    "            try:\n",
    "                if 'tripid' in line_gdf.columns:\n",
    "                    match = line_gdf[line_gdf['tripid'] == tripid]\n",
    "                    if match.empty:\n",
    "                        match = None\n",
    "                else:\n",
    "                    match = None\n",
    "            except Exception:\n",
    "                match = None\n",
    "        if match is None:\n",
    "            try:\n",
    "                match = line_gdf.iloc[[0]] if 'line_gdf' in globals() and len(line_gdf) > 0 else None\n",
    "            except Exception:\n",
    "                match = None\n",
    "\n",
    "        if match is None or match.empty:\n",
    "            print(f'No geometry found for trip {tripid} (rank {rank}) in city {city}; skipping.')\n",
    "            continue\n",
    "\n",
    "        fname = out_dir / f\"{rank:03d}_{safe(tripid)}_{safe(city)}.png\"\n",
    "\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "        try:\n",
    "            if 'poly_gdf' in globals():\n",
    "                try:\n",
    "                    single_poly = poly_gdf[poly_gdf['tripid'] == tripid] if 'tripid' in poly_gdf.columns else poly_gdf.iloc[[match.index[0]]]\n",
    "                except Exception:\n",
    "                    single_poly = poly_gdf.iloc[[match.index[0]]] if len(poly_gdf) > match.index[0] else None\n",
    "                if single_poly is not None and not single_poly.empty:\n",
    "                    single_poly.to_crs(epsg=3857).plot(ax=ax, color='orange', alpha=0.4, edgecolor='darkorange')\n",
    "            match.to_crs(epsg=3857).plot(ax=ax, color='red', linewidth=3)\n",
    "            minx, miny, maxx, maxy = match.to_crs(epsg=3857).total_bounds\n",
    "            buf = max((maxx - minx), (maxy - miny)) * 0.25 if maxx > minx and maxy > miny else 200\n",
    "            ax.set_xlim(minx - buf, maxx + buf)\n",
    "            ax.set_ylim(miny - buf, maxy + buf)\n",
    "            try:\n",
    "                import contextily as ctx\n",
    "                ctx.add_basemap(ax)\n",
    "            except Exception:\n",
    "                pass\n",
    "            ax.set_axis_off()\n",
    "            ax.set_title(f'Rank {rank} — Trip {tripid} — {city}')\n",
    "            fig.savefig(fname, dpi=150, bbox_inches='tight')\n",
    "            plt.close(fig)\n",
    "            print(f'Saved {fname}')\n",
    "        except Exception as e:\n",
    "            print(f'Failed to save route {tripid} (rank {rank}) for city {city}: {e}')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
